imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

api:
  enabled: true
  replicaCount: 1

  image:
    repository: ghcr.io/climate-ref/climate-ref-frontend
    pullPolicy: IfNotPresent
    tag: main

  env:
    ENVIRONMENT: production
    LOG_LEVEL: INFO
    SECRET_KEY: changethis          # Must override in production
    REF_DATABASE_URL: ""            # Required: e.g. postgresql://user:pass@host:5432/db or sqlite:////path/to/db
    REF_CONFIGURATION: /app/.ref

  ingress:
    enabled: false
    host:
    className: ""
    annotations: {}
    labels: {}

  httpRoute:
    enabled: false
    hostnames: []
    parentRefs: []
    annotations: {}
    labels: {}

  serviceAccount:
    create: true
    automount: false
    annotations: {}
    name: ""

  podAnnotations: {}
  podLabels: {}

  podSecurityContext: {}

  securityContext:
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
    runAsNonRoot: true

  service:
    type: ClusterIP
    port: 80

  resources: {}

  volumes: []
  volumeMounts: []
  nodeSelector: {}
  tolerations: []
  affinity: {}

dragonfly:
  storage:
    enabled: true

flower:
  env:
    CELERY_BROKER_URL: redis://{{ include "dragonfly.fullname" .Subcharts.dragonfly }}:{{ .Values.dragonfly.service.port }}
    CELERY_RESULT_BACKEND: redis://{{ include "dragonfly.fullname" .Subcharts.dragonfly }}:{{ .Values.dragonfly.service.port }}

  # Additional Celery configuration for Flower (rendered as celeryconfig.py)
  # Use this for settings that cannot be set via environment variables
  celeryConfig: |
    accept_content = ['application/json', 'application/x-python-serialize']

  ingress:
    enabled: false
    host:
    className: ""
    annotations: {}
    labels: {}

  httpRoute:
    enabled: false
    hostnames: []
    parentRefs: []
    annotations: {}
    labels: {}

  serviceMonitor:
    enabled: false

  replicaCount: 1

  image:
    repository: mher/flower
    pullPolicy: IfNotPresent
    tag: 2.0.1

  serviceAccount:
    create: true
    automount: false
    annotations: {}
    name: ""

  podAnnotations: {}
  podLabels: {}

  podSecurityContext: {}

  securityContext:
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
    runAsNonRoot: true

  service:
    type: ClusterIP
    port: 5555

  resources: {}

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  volumes: []
  volumeMounts: []
  nodeSelector: {}
  tolerations: []
  affinity: {}

# A mapping of name: size for PVCs to create. Name will be prepended with release name.
# Not mounted unless specified in volumes and volumeMounts arrays
createPVCs: {}

defaults:
  env:
    CELERY_BROKER_URL: redis://{{ include "dragonfly.fullname" .Subcharts.dragonfly }}:{{ .Values.dragonfly.service.port }}
    CELERY_RESULT_BACKEND: redis://{{ include "dragonfly.fullname" .Subcharts.dragonfly }}:{{ .Values.dragonfly.service.port }}
    CELERY_ACCEPT_CONTENT: |
      ["json", "pickle"]
    REF_EXECUTOR: climate_ref_celery.executor.CeleryExecutor
    # Set HOME to writable location to fix intake-esgf and ilamb3 config directory creation
    HOME: /tmp
    # Celery reliability tuning (uncomment to override base.py defaults)
    # CELERY_TASK_TIME_LIMIT: "21600"          # Hard kill after 6 hours
    # CELERY_TASK_SOFT_TIME_LIMIT: "19800"     # Soft limit at 5.5 hours
    # CELERY_VISIBILITY_TIMEOUT: "21600"       # Must be >= CELERY_TASK_TIME_LIMIT
    # CELERY_WORKER_PREFETCH_MULTIPLIER: "1"
    # CELERY_RESULT_EXPIRES: "172800"          # 48 hours
    # CELERY_WORKER_MAX_TASKS_PER_CHILD: "50"  # Recycle workers to prevent memory leaks
    # CELERY_WORKER_MAX_MEMORY_PER_CHILD: "2097152"  # 2 GB cap per worker process (in KB)

  replicaCount: 1

  image:
    repository: ghcr.io/climate-ref/climate-ref
    pullPolicy: IfNotPresent
    tag: v0.11.1

  annotations: {}

  serviceAccount:
    create: true
    automount: false
    annotations: {}
    name: ""

  podAnnotations: {}
  podLabels: {}

  podSecurityContext:
    fsGroup: 1000

  securityContext:
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
    runAsNonRoot: true

  service:
    type: ClusterIP
    port: 80

  resources: {}

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  volumes: []
  volumeMounts: []
  nodeSelector: {}
  tolerations: []
  affinity: {}

# Map of instances to deploy, where the key is the instance name and the value
# is any provider-specific overrides.
#
#  If no overrides are provided, the provider will be deployed with the defaults above.
#
# Per-provider time limits can be set via env overrides. For example:
#   esmvaltool:
#     env:
#       CELERY_TASK_TIME_LIMIT: "21600"       # 6 hours
#       CELERY_TASK_SOFT_TIME_LIMIT: "19800"   # 5.5 hours
#       CELERY_VISIBILITY_TIMEOUT: "21600"
#   ilamb:
#     env:
#       CELERY_TASK_TIME_LIMIT: "1800"         # 30 minutes
#       CELERY_TASK_SOFT_TIME_LIMIT: "1500"    # 25 minutes
#       CELERY_VISIBILITY_TIMEOUT: "1800"
providers:
  orchestrator: {}
  esmvaltool: {}
  pmp: {}
  ilamb: {}
